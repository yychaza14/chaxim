name: Bybit and binance P2P Data Collection

on:
  schedule:
    # Run every hour
    - cron: '0 * * * *'
  workflow_dispatch:  # Allows manual triggering

jobs:
  collect-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Explicitly grant write permission
    

    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0
        # Use token with write permissions
        token: ${{ secrets.PAT }}

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: Update package lists and upgrade packages
      run: |
        sudo apt-get update
        sudo apt-get upgrade -y
      continue-on-error: true

    - name: Install Chrome and ChromeDriver
      run: |
        # Install or update Chrome
        wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/google.gpg
        echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google.list
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable || echo "Chrome is already installed"
          
        # Install matching ChromeDriver version
        CHROME_VERSION=$(google-chrome --version | cut -d ' ' -f3 | cut -d '.' -f1)
        CHROMEDRIVER_VERSION=$(curl -s "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_$CHROME_VERSION")
        
        # Only download and install ChromeDriver if not already present or if version mismatch
        if ! command -v chromedriver &> /dev/null || \
           [[ $(chromedriver --version | cut -d ' ' -f2 | cut -d '.' -f1) != $CHROME_VERSION ]]; then
          wget -q "https://chromedriver.storage.googleapis.com/${CHROMEDRIVER_VERSION}/chromedriver_linux64.zip"
          unzip -o chromedriver_linux64.zip
          sudo mv -f chromedriver /usr/local/bin/
          sudo chmod +x /usr/local/bin/chromedriver
        fi
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install selenium requests pandas openpyxl
    
    - name: Run scraper
      run: python main.py
      env:
        PYTHONUNBUFFERED: 1

     
      
    - name: Commit and push if there are changes
      run: |
        # Configure git
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        
        # Stash any changes
        git stash
        
        # Pull latest changes
        git pull origin main
        
        # Pop stashed changes
        git stash pop
        
        # Add and commit new changes
        git add pb2b/
        timestamp=$(date -u +'%Y-%m-%d %H:%M:%S UTC')
        git commit -m "Update P2P data ${timestamp}" || echo "No changes to commit"
        
        # Push changes
        git push origin main
        
      env:
        GITHUB_TOKEN: ${{ secrets.PAT }}

      
